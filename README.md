# ğŸ“ Emotion-Sensing Learning Assistant (ESLA)

An AI-powered web application that detects a student's **emotion** using real-time **facial expressions** and **voice input**, then recommends **engaging activities** and **YouTube videos** to help teachers tailor the learning experience.

---

##  Project Overview

**ESLA** is designed to make digital classrooms more emotionally aware. It:
- Detects student emotions in real time using webcam and microphone.
- Suggests activities through OpenAI based on emotion (e.g., games, questions, discussions).
- Recommends matching videos from YouTube to boost engagement.
- Logs and visualizes emotion trends for teachers using dashboards.

This project was developed as part of **Intel Unnati Training 2025** to showcase the impact of **AI in education**.

---

##  Features
- ğŸ¥ **Facial Emotion Detection** (via webcam)
- ğŸ™ï¸ **Voice Emotion Recognition** (via mic input)
- ğŸ”— **Activity Suggestions** (via OpenAI API)
- ğŸ“º **YouTube Video Recommender**
- ğŸ“Š **Live Dashboard** with emotion logs and trend graphs
- ğŸ–¥ï¸ **Streamlit Frontend** with custom CSS

---

## ğŸ› ï¸ Tech Stack
| Layer             | Tools & Libraries                      |
|------------------|----------------------------------------|
| Programming      | Python                                 |
| Emotion Detection| DeepFace, OpenVINO, TensorFlow          |
| Audio Processing | SpeechRecognition, PyAudio, librosa     |
| ML Conversion    | ONNX, Keras                             |
| Frontend         | Streamlit, HTML, CSS                    |
| Visualization    | Matplotlib, Streamlit Charts            |
| AI Services      | OpenAI GPT API, YouTube Search API      |

---

## ğŸ“‚ Folder Structure
â”œâ”€â”€ main.py # Main app logic and routing
â”œâ”€â”€ facial_emotion.py # Facial emotion detection
â”œâ”€â”€ voice_emotion.py # Voice emotion recognition
â”œâ”€â”€ fuse.py # Combine face + voice predictions
â”œâ”€â”€ webcam_emotion_live.py # Webcam input and detection
â”œâ”€â”€ mic_record.py # Voice input and processing
â”œâ”€â”€ learning.py # OpenAI-based suggestions
â”œâ”€â”€ dashboard.py # Emotion graphs and trend visualization
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ models/ # Pre-trained and converted models
â”œâ”€â”€ screenshots/ # App screenshots (optional)
â””â”€â”€ assets/ # Icons, stylesheets, etc.

---

## ğŸš€ How to Run
1. Clone the Repository
bash
Copy
Edit
git clone https://github.com/Saisha16/Emotion-Sensing-Learning-Assistant.git
cd Emotion-Sensing-Learning-Assistant
2. Install Requirements
Make sure Python 3.8+ is installed.

bash
Copy
Edit
pip install -r requirements.txt
3. Run the App
bash
Copy
Edit
streamlit run main.py
âœ… Make sure your microphone and webcam are enabled when prompted.
ğŸ” Emotion Categories
Happy ğŸ˜Š

Sad ğŸ˜¢

Angry ğŸ˜ 

Neutral ğŸ˜

Fearful ğŸ˜¨

Surprised ğŸ˜²

ğŸ“ˆ Dashboard Preview
Pie chart of emotion distribution

Line graph showing emotion trends

Logs of past detections with timestamp

Note: Video is in EmotionSensingVideo Folder
ğŸ”® Future Enhancements
Group emotion analysis

Multilingual voice support

LMS integration (Google Classroom, Moodle)

Deploy as Dockerized web app

Fine-tuned GPT prompts for subject-specific activities

ğŸ“œ License
MIT License Â© 2025 IÂ²nsane Coders

ğŸ‘¥ Contributors
Saisha16
Ishta13
IÂ²nsane Coders

